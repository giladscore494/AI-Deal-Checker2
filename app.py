# -*- coding: utf-8 -*-
# ===========================================================
# AI Deal Checker â€“ ×’×¨×¡×” ×¡×•×¤×™×ª ×•××¦×•×—×¦×—×ª (Gemini 2.5 Flash)
# ×›×•×œ×œ × ×™×ª×•×— ×¢×§×‘×™×•×ª, ×ª×™×§×•×Ÿ ×©×•×§, 18 ××§×¨×™ ×§×¦×”, ×•×©××™×¨×” ×‘-Google Sheets
# ===========================================================

import streamlit as st
import google.generativeai as genai
import gspread, json, os, re, traceback
from google.oauth2.service_account import Credentials
from json_repair import repair_json
from PIL import Image
import pandas as pd
from datetime import datetime

# ---------- ×”×’×“×¨×•×ª ×›×œ×œ×™×•×ª ----------
st.set_page_config(page_title="AI Deal Checker ğŸš—", page_icon="ğŸš—", layout="centered")

# ---------- ×—×™×‘×•×¨ ×œ-Gemini ----------
api_key = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.5-flash")

# ---------- ×—×™×‘×•×¨ ×œ-Google Sheets ----------
SHEET_ID = st.secrets.get("GOOGLE_SHEET_ID")
SERVICE_ACCOUNT_JSON = st.secrets.get("GOOGLE_SERVICE_ACCOUNT_JSON")
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
sheet = None

try:
    creds = Credentials.from_service_account_info(SERVICE_ACCOUNT_JSON, scopes=SCOPES)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(SHEET_ID).sheet1
    st.success("âœ… ×–×™×›×¨×•×Ÿ AI ××—×•×‘×¨ ×‘×”×¦×œ×—×” â€“ × ×ª×•× ×™× × ×©××¨×™× ×œ×¢× ×Ÿ.")
except Exception:
    st.warning("âš ï¸ ×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ×–×™×›×¨×•×Ÿ AI, ×ª×ª×‘×¦×¢ ×©××™×¨×” ××§×•××™×ª ×‘×œ×‘×“.")
    sheet = None

LOCAL_FILE = "data_history.json"

# ---------- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ----------
def load_history():
    """×§×¨×™××ª × ×ª×•× ×™× ××”×©×™×˜×¡ ××• ××§×•×‘×¥ ××§×•××™."""
    if sheet:
        try:
            data = sheet.get_all_records()
            return [json.loads(row["data_json"]) for row in data if row.get("data_json")]
        except Exception:
            pass
    if os.path.exists(LOCAL_FILE):
        with open(LOCAL_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_to_history(entry):
    """×©××™×¨×” ×œ×©×™×˜×¡ ××• fallback ××§×•××™."""
    try:
        if sheet:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            flat_entry = [
                timestamp,
                entry["from_ad"].get("brand", ""),
                entry["from_ad"].get("model", ""),
                entry["from_ad"].get("year", ""),
                entry.get("deal_score", ""),
                entry.get("classification", ""),
                entry["from_ad"].get("price_nis", ""),
                entry.get("short_verdict", "")
            ]
            sheet.append_row(flat_entry)
        else:
            data = load_history()
            data.append(entry)
            with open(LOCAL_FILE, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×©××™×¨×”: {e}")

def get_model_avg(brand, model_name):
    history = load_history()
    scores = [
        h.get("deal_score") for h in history
        if h.get("from_ad", {}).get("brand", "").lower() == brand.lower()
        and model_name.lower() in h.get("from_ad", {}).get("model", "").lower()
    ]
    scores = [s for s in scores if isinstance(s, (int, float))]
    return round(sum(scores)/len(scores), 2) if scores else None

def check_consistency(brand, model_name):
    history = load_history()
    relevant = [
        h.get("deal_score") for h in history
        if h.get("from_ad", {}).get("brand", "").lower() == brand.lower()
        and model_name.lower() in h.get("from_ad", {}).get("model", "").lower()
    ]
    relevant = [s for s in relevant if isinstance(s, (int, float))]
    if len(relevant) >= 3 and max(relevant) - min(relevant) >= 25:
        return True, relevant
    return False, relevant

def guess_brand_model(text):
    if not text:
        return "", ""
    tokens = [t for t in re.split(r"[^\w\u0590-\u05FF\-]+", text.splitlines()[0]) if t]
    if len(tokens) >= 2:
        return tokens[0], " ".join(tokens[1:3])
    return "", ""

# ---------- ×××©×§ ----------
st.title("ğŸš— AI Deal Checker")
st.caption("×‘×“×•×§ ×›×“××™×•×ª ×©×œ ××•×“×¢×•×ª ×¨×›×‘ ××©×•××© ×¢× × ×™×ª×•×— ××‘×•×¡×¡ ×‘×™× ×” ××œ××›×•×ª×™×ª")

ad_text = st.text_area("ğŸ“‹ ×”×“×‘×§ ×›××Ÿ ××ª ×˜×§×¡×˜ ×”××•×“×¢×”:", height=250)
uploaded_images = st.file_uploader("ğŸ“¸ ×”×¢×œ×” ×ª××•× ×•×ª ×©×œ ×”×¨×›×‘ (×œ× ×—×•×‘×”):", type=["jpg","jpeg","png"], accept_multiple_files=True)

st.markdown(
    """
    <div style='background-color:#fff3cd; border-radius:10px; padding:10px; border:1px solid #ffeeba;'>
    âš ï¸ <b>×”×‘×”×¨×”:</b> × ×™×ª×•×— ×–×” ××‘×•×¡×¡ ×‘×™× ×” ××œ××›×•×ª×™×ª ×•××™× ×• ×ª×—×œ×™×£ ×œ×‘×“×™×§×” ××§×¦×•×¢×™×ª. ××•××œ×¥ ×œ×‘×¦×¢ ×‘×“×™×§×ª ××•×¡×š ××œ××” ×œ×¤× ×™ ×¨×›×™×©×”.
    </div>
    """,
    unsafe_allow_html=True
)

# ---------- ×¤×¢×•×œ×” ----------
if st.button("×—×©×‘ ×¦×™×•×Ÿ ×›×“××™×•×ª"):
    if not ad_text.strip():
        st.error("×× × ×”×“×‘×§ ×˜×§×¡×˜ ×©×œ ××•×“×¢×”.")
        st.stop()

    with st.spinner("ğŸ” ××—×©×‘ ××ª ×›×“××™×•×ª ×”×¢×¡×§×”..."):
        try:
            g_brand, g_model = guess_brand_model(ad_text)
            consistency_alert, prev_scores = check_consistency(g_brand, g_model)
            stability_note = f"âš ï¸ ×–×•×”×ª×” ××™-×¢×§×‘×™×•×ª ×‘×¦×™×•× ×™× ×§×•×“××™× ×œ×“×’× ×–×” ({prev_scores})." if consistency_alert else ""

            prompt = f"""
××ª×” ×× ×œ×™×¡×˜ ××•××—×” ×œ×©×•×§ ×”×¨×›×‘ ×”×™×©×¨××œ×™. ×”×¢×¨×š ××ª ×›×“××™×•×ª ×”×¢×¡×§×” ×œ××•×“×¢×” ×”×‘××”.
{stability_note}

--- ×©×œ×‘×™ ×”× ×™×ª×•×— ---
1. × ×ª×— ××ª ×˜×§×¡×˜ ×”××•×“×¢×” ×•×”×¤×§ × ×ª×•× ×™×: ×™×¦×¨×Ÿ, ×“×’×, ×©× ×”, ××—×™×¨, ×§×´×, ×¨××ª ×’×™××•×¨, ××¦×‘ ×›×œ×œ×™.
2. ××¦× × ×ª×•× ×™ ×©×•×§ ×××•×¦×¢×™× ×œ×“×’× ×–×” (××—×™×¨, ×××™× ×•×ª, ×ª×—×–×•×§×”, ×ª×§×œ×•×ª ×™×“×•×¢×•×ª, ×‘×™×§×•×©).
3. ×”×©×•×•×” ×‘×™×Ÿ ×”××™×“×¢ ××”××•×“×¢×” ×œ× ×ª×•× ×™ ×”×©×•×§.
4. ×”×©×ª××© ×‘Ö¾18 ××§×¨×™ ×”×§×¦×” ×œ×”×™×× ×¢×•×ª ××©×’×™××•×ª:
5.×”×—×–×¨ ×ª×©×•×‘×•×ª ×¨×§ ×‘×¢×‘×¨×™×ª ×¨×”×•×˜×” ×•××¡×•×“×¨×ª
   - ×§×´× ×’×‘×•×” ××š ××˜×•×¤×œ = ×ª×§×™×Ÿ
   - ××—×™×¨ × ××•×š ×¢×“ 10% = ×œ× ×—×©×•×“
   - ××—×™×¨ ×’×‘×•×” ××•×¦×“×§ ×× ×¨××” ×××•×‘×–×¨×ª
   - ×¨×›×‘ ×©×˜×— = ×§×´× ×’×‘×•×” × ×•×¨××œ×™
   - ×¨×›×‘ × ×™×©×” â€“ ×œ× ×œ×¤×™ ×‘×™×§×•×©
   - × ×™×¡×•×— ×¨×©×œ× ×™ â€“ ×œ× ×©×œ×™×œ×”
   - ××•×“×¢×” ×§×¦×¨×” â€“ ×”×©×œ× ××™×“×¢
   - ××—×™×¨ × ××•×š ×‘Ö¾50% = ×—×©×“ ×”×©×‘×ª×”
   - ×™×‘×•× ××™×©×™ â€“ ××œ ×ª×©×•×•×” ×¨×’×™×œ
   - ××¡×¤× ×•×ª â€“ ×’×™×œ ×œ× ×—×™×¡×¨×•×Ÿ
   - ×¡×•×—×¨ â€“ ×”×¤×—×ª ×××™× ×•×ª
   - â€œ××—×™×¨ ×¡×•×¤×™â€ â€“ ×œ× ×‘×”×›×¨×— ×©×œ×™×œ×™
   - ×¦×‘×¢ ×—×¨×™×’ â€“ ×× ××§×•×¨×™ ×œ× ×—×™×¡×¨×•×Ÿ
   - ××™×Ÿ ×§×´× â€“ ×”×¢×¨×š ×××•×¦×¢
   - ××–×•×¨ ×œ×— â€“ ×¡×™×›×•×Ÿ ×—×œ×•×“×”
   - ×—×¡×¨ ××—×™×¨ â€“ ×”×¢×¨×š ×œ×¤×™ ×××•×¦×¢
   - ×œ×™×¡×™× ×’ ×©×˜×•×¤×œ â€“ ×ª×§×™×Ÿ
   - ×©×¤×” ×–×¨×” â€“ ×”×¡×ª××š ×¢×œ × ×ª×•× ×™× ×‘×œ×‘×“

--- × ×•×¡×—×ª ×”×¦×™×•×Ÿ (0â€“100) ---
- ××—×™×¨ ××•×œ ×©×•×§ â€“ 25%
- ×ª×—×–×•×§×” ×•××¦×‘ â€“ 25%
- ×××™× ×•×ª ×“×’× â€“ 20%
- ×’×™×œ ×•×§×´× â€“ 15%
- ×××™× ×•×ª ××•×›×¨ â€“ 10%
- ×‘×™×§×•×© â€“ 5%

×¡×¤×§ ×¤×œ×˜ JSON ×‘×œ×‘×“ ×‘×¤×•×¨××˜:
{{
  "from_ad": {{"brand":"", "model":"", "year":0, "mileage_km":0, "price_nis":0}},
  "deal_score": 0,
  "classification": "",
  "short_verdict": "",
  "key_reasons": [],
  "user_info": {{"reliability_summary":"", "maintenance_tips":[], "common_faults":[], "market_context":""}}
}}

××•×“×¢×”:
\"\"\"{ad_text}\"\"\"
"""

            inputs = [prompt]
            for img in uploaded_images or []:
                try:
                    inputs.append(Image.open(img))
                except Exception:
                    pass

            response = model.generate_content(inputs, request_options={"timeout": 120})
            fixed_json = repair_json(response.text or "")
            data = json.loads(fixed_json)

            avg = get_model_avg(data["from_ad"].get("brand",""), data["from_ad"].get("model",""))
            if avg:
                diff = data["deal_score"] - avg
                if abs(diff) >= 15:
                    data["deal_score"] = int(data["deal_score"] - diff * 0.5)
                    data["short_verdict"] += f" âš™ï¸ ×‘×•×¦×¢ ×ª×™×§×•×Ÿ ×œ×¤×™ ×××•×¦×¢ ×”×™×¡×˜×•×¨×™ ({avg})."

            save_to_history(data)

            # ---------- ×ª×¦×•×’×” ----------
            score = data.get("deal_score", 0)
            color = "#28a745" if score >= 80 else "#ffc107" if score >= 60 else "#dc3545"
            st.markdown(f"<h2 style='color:{color};text-align:center;'>ğŸš¦ ×¦×™×•×Ÿ ×”×¢×¡×§×”: {score}/100</h2>", unsafe_allow_html=True)
            st.markdown(f"<h4 style='text-align:center;'>{data.get('classification','')}</h4>", unsafe_allow_html=True)
            st.write("ğŸ§¾", data.get("short_verdict",""))

            st.divider()
            st.subheader("ğŸ’¡ ×¢×¨×š ××•×¡×£ ×œ××©×ª××©")
            info = data.get("user_info", {})
            if info.get("reliability_summary"):
                st.write(f"**×××™× ×•×ª ×”×“×’×:** {info['reliability_summary']}")
            if info.get("common_faults"):
                st.write("**×ª×§×œ×•×ª × ×¤×•×¦×•×ª:**")
                for fault in info["common_faults"]:
                    st.write(f"â€¢ {fault}")
            if info.get("maintenance_tips"):
                st.write("**×˜×™×¤×™× ×œ×ª×—×–×•×§×”:**")
                for tip in info["maintenance_tips"]:
                    st.write(f"â€¢ {tip}")
            if info.get("market_context"):
                st.write("**×”×§×©×¨ ×©×•×§ ×›×œ×œ×™:**", info["market_context"])

            st.subheader("ğŸ¯ ×¡×™×‘×•×ª ×¢×™×§×¨×™×•×ª ×œ×¦×™×•×Ÿ")
            for reason in data.get("key_reasons", []):
                st.markdown(f"- {reason}")

            st.caption("Â© 2025 Car Advisor AI â€“ ×’×¨×¡×” ×œ×•××“×ª ×¢× ×—×™×‘×•×¨ ×–×™×›×¨×•×Ÿ ×—×›× ×œ-Google Sheets")

        except Exception:
            st.error("âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”× ×ª×•× ×™×.")
            st.code(traceback.format_exc())
